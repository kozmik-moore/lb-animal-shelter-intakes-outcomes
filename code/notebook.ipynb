{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ed569dd",
   "metadata": {},
   "source": [
    "# Project: Long Beach Animal Shelter Intakes and Outcomes\n",
    "\n",
    "## Description\n",
    "\n",
    "**Objective**: \\\n",
    "\\\n",
    "Answer questions for various shareholders in the city of Long Beach, CA concerning intakes and outcomes at the local animal shelter.\n",
    "\n",
    "**Dataset**: \\\n",
    "\\\n",
    "This dataset was pulled from the [Long Beach Open Data Portal](https://data.longbeach.gov/explore/dataset/animal-shelter-intakes-and-outcomes/). \\\n",
    "It is a 7.8MB CSV file containing intake and outcome data for animals captured by or surrendered to the city.\n",
    "\n",
    "**Tools Used**:\n",
    "\n",
    "- pandas\n",
    "- Matplotlib\n",
    "- Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44185ada",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "For any city that has at least one animal shelter, there are various shareholders interested in how that shelter is run and what happens to the animals that pass through the shelter's doors.\\\n",
    "\\\n",
    "This analysis looks to answer questions for the following parties in Long Beach, CA:\n",
    "- **Shelter managers:**\n",
    "  - How long do animals typically stay in the shelter by species or intake condition?\n",
    "  - What intake reasons are most strongly correlated with negative outcomes (e.g., euthanasia)?\n",
    "  - Are there seasonal trends in animal intakes or outcomes?\n",
    "- **Animal welfare advocates:**\n",
    "  - What percentage of animals are adopted vs. euthanized, and how does that vary by type, sex, or condition?\n",
    "  - Are there disparities in outcomes for specific breeds or geographic areas?\n",
    "  - How many animals are returned to owners vs. adopted?\n",
    "- **Local government officials:**\n",
    "  - Is there a correlation between specific neighborhoods and high intake rates?\n",
    "  - Has the shelter’s performance improved over time (e.g., reduced euthanasia rates)?\n",
    "  - What’s the annual intake/output volume and trend?\n",
    "- **Local citizenry:**\n",
    "  - When is the best time of year to adopt (e.g., more animals available)?\n",
    "  - What types of animals are most commonly available for adoption?\n",
    "  - Can geographic patterns inform community outreach for fostering or adoption?\n",
    "- **Internal analysts:**\n",
    "  - What features best predict positive outcomes using logistic regression or clustering?\n",
    "  - Can intake condition be used to forecast outcome types?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a7d530",
   "metadata": {},
   "source": [
    "# Data handling\n",
    "\n",
    "## Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f170f70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "# Import helper functions and variables\n",
    "from utilities.config import get_path_obj, raw_data_path, processed_data_path, products_dir, images_dir, data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "629bce47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal ID</th>\n",
       "      <th>Animal Name</th>\n",
       "      <th>Animal Type</th>\n",
       "      <th>Primary Color</th>\n",
       "      <th>Secondary Color</th>\n",
       "      <th>Sex</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Intake Date</th>\n",
       "      <th>Intake Condition</th>\n",
       "      <th>Intake Type</th>\n",
       "      <th>...</th>\n",
       "      <th>Outcome Type</th>\n",
       "      <th>Outcome Subtype</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>intake_is_dead</th>\n",
       "      <th>outcome_is_dead</th>\n",
       "      <th>was_outcome_alive</th>\n",
       "      <th>geopoint</th>\n",
       "      <th>intake_duration</th>\n",
       "      <th>is_current_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A594350</td>\n",
       "      <td>*HEAVY CREAM</td>\n",
       "      <td>CAT</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutered</td>\n",
       "      <td>2014-07-28</td>\n",
       "      <td>2017-07-28</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>STRAY</td>\n",
       "      <td>...</td>\n",
       "      <td>ADOPTION</td>\n",
       "      <td>REPEAT ADT</td>\n",
       "      <td>33.799760</td>\n",
       "      <td>-118.126388</td>\n",
       "      <td>Alive on Intake</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>33.7997598, -118.1263884</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A347815</td>\n",
       "      <td>DUKE</td>\n",
       "      <td>DOG</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>TAN</td>\n",
       "      <td>Neutered</td>\n",
       "      <td>2005-04-14</td>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>OWNER SURRENDER</td>\n",
       "      <td>...</td>\n",
       "      <td>RESCUE</td>\n",
       "      <td>LIVELOVE</td>\n",
       "      <td>33.799760</td>\n",
       "      <td>-118.126388</td>\n",
       "      <td>Alive on Intake</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>33.7997598, -118.1263884</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A707449</td>\n",
       "      <td>*TABITHA</td>\n",
       "      <td>DOG</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>Spayed</td>\n",
       "      <td>2022-10-23</td>\n",
       "      <td>2023-09-23</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>STRAY</td>\n",
       "      <td>...</td>\n",
       "      <td>ADOPTION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.798953</td>\n",
       "      <td>-118.167334</td>\n",
       "      <td>Alive on Intake</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>33.7989532, -118.167334</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A712850</td>\n",
       "      <td>*KIWI</td>\n",
       "      <td>DOG</td>\n",
       "      <td>BLONDE</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>Spayed</td>\n",
       "      <td>2022-07-06</td>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>RETURN</td>\n",
       "      <td>...</td>\n",
       "      <td>ADOPTION</td>\n",
       "      <td>WEB</td>\n",
       "      <td>33.798936</td>\n",
       "      <td>-118.195889</td>\n",
       "      <td>Alive on Intake</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>33.7989357, -118.1958891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A738972</td>\n",
       "      <td>KITTEN 2</td>\n",
       "      <td>CAT</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2025-03-28</td>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>STRAY</td>\n",
       "      <td>...</td>\n",
       "      <td>RESCUE</td>\n",
       "      <td>LITTLELION</td>\n",
       "      <td>33.798936</td>\n",
       "      <td>-118.195889</td>\n",
       "      <td>Alive on Intake</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>33.7989357, -118.1958891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Animal ID   Animal Name Animal Type Primary Color Secondary Color       Sex  \\\n",
       "0   A594350  *HEAVY CREAM         CAT         BLACK             NaN  Neutered   \n",
       "1   A347815          DUKE         DOG         BLACK             TAN  Neutered   \n",
       "2   A707449      *TABITHA         DOG         BLACK           WHITE    Spayed   \n",
       "3   A712850         *KIWI         DOG        BLONDE            GOLD    Spayed   \n",
       "4   A738972      KITTEN 2         CAT         BLACK             NaN   Unknown   \n",
       "\n",
       "         DOB Intake Date Intake Condition      Intake Type  ... Outcome Type  \\\n",
       "0 2014-07-28  2017-07-28           NORMAL            STRAY  ...     ADOPTION   \n",
       "1 2005-04-14  2018-11-30           NORMAL  OWNER SURRENDER  ...       RESCUE   \n",
       "2 2022-10-23  2023-09-23           NORMAL            STRAY  ...     ADOPTION   \n",
       "3 2022-07-06  2024-02-03           NORMAL           RETURN  ...     ADOPTION   \n",
       "4 2025-03-28  2025-04-04           NORMAL            STRAY  ...       RESCUE   \n",
       "\n",
       "  Outcome Subtype   latitude   longitude   intake_is_dead outcome_is_dead  \\\n",
       "0      REPEAT ADT  33.799760 -118.126388  Alive on Intake           False   \n",
       "1        LIVELOVE  33.799760 -118.126388  Alive on Intake           False   \n",
       "2             NaN  33.798953 -118.167334  Alive on Intake           False   \n",
       "3             WEB  33.798936 -118.195889  Alive on Intake           False   \n",
       "4      LITTLELION  33.798936 -118.195889  Alive on Intake           False   \n",
       "\n",
       "  was_outcome_alive                  geopoint  intake_duration  \\\n",
       "0                 1  33.7997598, -118.1263884             81.0   \n",
       "1                 1  33.7997598, -118.1263884             27.0   \n",
       "2                 1   33.7989532, -118.167334             18.0   \n",
       "3                 1  33.7989357, -118.1958891              0.0   \n",
       "4                 1  33.7989357, -118.1958891              0.0   \n",
       "\n",
       "  is_current_month  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(raw_data_path, parse_dates=['DOB', 'Intake Date', 'Outcome Date'],)\n",
    "\n",
    "# Preview\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd274c44",
   "metadata": {},
   "source": [
    "### Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "832bc8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Animal ID                    object\n",
       "Animal Name                  object\n",
       "Animal Type                  object\n",
       "Primary Color                object\n",
       "Secondary Color              object\n",
       "Sex                          object\n",
       "DOB                  datetime64[ns]\n",
       "Intake Date          datetime64[ns]\n",
       "Intake Condition             object\n",
       "Intake Type                  object\n",
       "Intake Subtype               object\n",
       "Reason for Intake            object\n",
       "Outcome Date         datetime64[ns]\n",
       "Crossing                     object\n",
       "Jurisdiction                 object\n",
       "Outcome Type                 object\n",
       "Outcome Subtype              object\n",
       "latitude                    float64\n",
       "longitude                   float64\n",
       "intake_is_dead               object\n",
       "outcome_is_dead                bool\n",
       "was_outcome_alive             int64\n",
       "geopoint                     object\n",
       "intake_duration             float64\n",
       "is_current_month              int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Animal ID', 'Animal Name', 'Animal Type', 'Primary Color',\n",
       "       'Secondary Color', 'Sex', 'DOB', 'Intake Date', 'Intake Condition',\n",
       "       'Intake Type', 'Intake Subtype', 'Reason for Intake', 'Outcome Date',\n",
       "       'Crossing', 'Jurisdiction', 'Outcome Type', 'Outcome Subtype',\n",
       "       'latitude', 'longitude', 'intake_is_dead', 'outcome_is_dead',\n",
       "       'was_outcome_alive', 'geopoint', 'intake_duration', 'is_current_month'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal ID</th>\n",
       "      <th>Animal Name</th>\n",
       "      <th>Animal Type</th>\n",
       "      <th>Primary Color</th>\n",
       "      <th>Secondary Color</th>\n",
       "      <th>Sex</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Intake Date</th>\n",
       "      <th>Intake Condition</th>\n",
       "      <th>Intake Type</th>\n",
       "      <th>...</th>\n",
       "      <th>Outcome Type</th>\n",
       "      <th>Outcome Subtype</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>intake_is_dead</th>\n",
       "      <th>outcome_is_dead</th>\n",
       "      <th>was_outcome_alive</th>\n",
       "      <th>geopoint</th>\n",
       "      <th>intake_duration</th>\n",
       "      <th>is_current_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>33707</td>\n",
       "      <td>19956</td>\n",
       "      <td>33707</td>\n",
       "      <td>33707</td>\n",
       "      <td>15964</td>\n",
       "      <td>33707</td>\n",
       "      <td>29433</td>\n",
       "      <td>33707</td>\n",
       "      <td>33707</td>\n",
       "      <td>33707</td>\n",
       "      <td>...</td>\n",
       "      <td>33374</td>\n",
       "      <td>29842</td>\n",
       "      <td>33707.000000</td>\n",
       "      <td>33707.000000</td>\n",
       "      <td>33707</td>\n",
       "      <td>33707</td>\n",
       "      <td>33707.000000</td>\n",
       "      <td>33707</td>\n",
       "      <td>33381.000000</td>\n",
       "      <td>33707.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>32557</td>\n",
       "      <td>9996</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>A637086</td>\n",
       "      <td>*</td>\n",
       "      <td>CAT</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>STRAY</td>\n",
       "      <td>...</td>\n",
       "      <td>RESCUE</td>\n",
       "      <td>SPCALA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alive on Intake</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.8096122, -118.0826161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>8</td>\n",
       "      <td>104</td>\n",
       "      <td>16083</td>\n",
       "      <td>8548</td>\n",
       "      <td>9380</td>\n",
       "      <td>7739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15297</td>\n",
       "      <td>23719</td>\n",
       "      <td>...</td>\n",
       "      <td>7842</td>\n",
       "      <td>4074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33707</td>\n",
       "      <td>26766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-11-03 22:44:42.295383040</td>\n",
       "      <td>2021-02-04 00:22:07.771679488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.815444</td>\n",
       "      <td>-118.149526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.794078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.741949</td>\n",
       "      <td>0.012075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993-09-15 00:00:00</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.297815</td>\n",
       "      <td>-122.695911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-09-16 00:00:00</td>\n",
       "      <td>2018-09-29 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.783990</td>\n",
       "      <td>-118.190865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-03-28 00:00:00</td>\n",
       "      <td>2021-01-02 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.806783</td>\n",
       "      <td>-118.173175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-04-06 00:00:00</td>\n",
       "      <td>2023-05-26 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.851210</td>\n",
       "      <td>-118.128915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-07-06 00:00:00</td>\n",
       "      <td>2025-07-15 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.521885</td>\n",
       "      <td>-73.992360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1410.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.139548</td>\n",
       "      <td>0.530849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.404379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.219301</td>\n",
       "      <td>0.109221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Animal ID Animal Name Animal Type Primary Color Secondary Color    Sex  \\\n",
       "count      33707       19956       33707         33707           15964  33707   \n",
       "unique     32557        9996          10            80              44      5   \n",
       "top      A637086           *         CAT         BLACK           WHITE   Male   \n",
       "freq           8         104       16083          8548            9380   7739   \n",
       "mean         NaN         NaN         NaN           NaN             NaN    NaN   \n",
       "min          NaN         NaN         NaN           NaN             NaN    NaN   \n",
       "25%          NaN         NaN         NaN           NaN             NaN    NaN   \n",
       "50%          NaN         NaN         NaN           NaN             NaN    NaN   \n",
       "75%          NaN         NaN         NaN           NaN             NaN    NaN   \n",
       "max          NaN         NaN         NaN           NaN             NaN    NaN   \n",
       "std          NaN         NaN         NaN           NaN             NaN    NaN   \n",
       "\n",
       "                                  DOB                    Intake Date  \\\n",
       "count                           29433                          33707   \n",
       "unique                            NaN                            NaN   \n",
       "top                               NaN                            NaN   \n",
       "freq                              NaN                            NaN   \n",
       "mean    2018-11-03 22:44:42.295383040  2021-02-04 00:22:07.771679488   \n",
       "min               1993-09-15 00:00:00            2017-01-01 00:00:00   \n",
       "25%               2016-09-16 00:00:00            2018-09-29 00:00:00   \n",
       "50%               2019-03-28 00:00:00            2021-01-02 00:00:00   \n",
       "75%               2022-04-06 00:00:00            2023-05-26 00:00:00   \n",
       "max               2025-07-06 00:00:00            2025-07-15 00:00:00   \n",
       "std                               NaN                            NaN   \n",
       "\n",
       "       Intake Condition Intake Type  ... Outcome Type Outcome Subtype  \\\n",
       "count             33707       33707  ...        33374           29842   \n",
       "unique               16          12  ...           18             240   \n",
       "top              NORMAL       STRAY  ...       RESCUE          SPCALA   \n",
       "freq              15297       23719  ...         7842            4074   \n",
       "mean                NaN         NaN  ...          NaN             NaN   \n",
       "min                 NaN         NaN  ...          NaN             NaN   \n",
       "25%                 NaN         NaN  ...          NaN             NaN   \n",
       "50%                 NaN         NaN  ...          NaN             NaN   \n",
       "75%                 NaN         NaN  ...          NaN             NaN   \n",
       "max                 NaN         NaN  ...          NaN             NaN   \n",
       "std                 NaN         NaN  ...          NaN             NaN   \n",
       "\n",
       "            latitude     longitude   intake_is_dead outcome_is_dead  \\\n",
       "count   33707.000000  33707.000000            33707           33707   \n",
       "unique           NaN           NaN                1               2   \n",
       "top              NaN           NaN  Alive on Intake           False   \n",
       "freq             NaN           NaN            33707           26766   \n",
       "mean       33.815444   -118.149526              NaN             NaN   \n",
       "min        19.297815   -122.695911              NaN             NaN   \n",
       "25%        33.783990   -118.190865              NaN             NaN   \n",
       "50%        33.806783   -118.173175              NaN             NaN   \n",
       "75%        33.851210   -118.128915              NaN             NaN   \n",
       "max        45.521885    -73.992360              NaN             NaN   \n",
       "std         0.139548      0.530849              NaN             NaN   \n",
       "\n",
       "       was_outcome_alive                  geopoint  intake_duration  \\\n",
       "count       33707.000000                     33707     33381.000000   \n",
       "unique               NaN                     10154              NaN   \n",
       "top                  NaN  33.8096122, -118.0826161              NaN   \n",
       "freq                 NaN                       570              NaN   \n",
       "mean            0.794078                       NaN        18.741949   \n",
       "min             0.000000                       NaN         0.000000   \n",
       "25%             1.000000                       NaN         0.000000   \n",
       "50%             1.000000                       NaN         5.000000   \n",
       "75%             1.000000                       NaN        16.000000   \n",
       "max             1.000000                       NaN      1410.000000   \n",
       "std             0.404379                       NaN        47.219301   \n",
       "\n",
       "       is_current_month  \n",
       "count      33707.000000  \n",
       "unique              NaN  \n",
       "top                 NaN  \n",
       "freq                NaN  \n",
       "mean           0.012075  \n",
       "min            0.000000  \n",
       "25%            0.000000  \n",
       "50%            0.000000  \n",
       "75%            0.000000  \n",
       "max            1.000000  \n",
       "std            0.109221  \n",
       "\n",
       "[11 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Structure and summary\n",
    "display(df.dtypes)\n",
    "display(df.columns)\n",
    "display(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "44667b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['animal_id', 'animal_name', 'animal_type', 'primary_color',\n",
       "       'secondary_color', 'sex', 'date_of_birth', 'intake_date',\n",
       "       'intake_condition', 'intake_type', 'intake_subtype',\n",
       "       'reason_for_intake', 'outcome_date', 'crossing', 'jurisdiction',\n",
       "       'outcome_type', 'outcome_subtype', 'latitude', 'longitude',\n",
       "       'intake_is_dead', 'outcome_is_dead', 'was_outcome_alive', 'geopoint',\n",
       "       'intake_duration', 'is_current_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns\n",
    "\n",
    "def rename(name: str):\n",
    "    \"\"\"Formats \"name\" by replacing spaces with underscores and changing the case to lower\n",
    "\n",
    "    Args:\n",
    "        name (str): the name to be formatted\n",
    "\n",
    "    Returns:\n",
    "        str: the formatted name\n",
    "    \"\"\"    \n",
    "    name = name.replace(' ', '_')\n",
    "    name = name.lower()\n",
    "    if name == 'dob':\n",
    "        name = 'date_of_birth'\n",
    "    return name\n",
    "\n",
    "df = df.rename(columns=rename)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b236547",
   "metadata": {},
   "source": [
    "### Variables (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "977fdcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['animal_type', 'primary_color', 'secondary_color', 'sex']\n",
      "['intake_condition', 'intake_type', 'intake_subtype', 'reason_for_intake', 'intake_is_dead']\n",
      "['outcome_type', 'outcome_subtype', 'outcome_is_dead', 'was_outcome_alive']\n",
      "['date_of_birth', 'intake_date', 'outcome_date', 'intake_duration', 'is_current_month']\n",
      "['latitude', 'longitude', 'geopoint', 'crossing', 'jurisdiction']\n"
     ]
    }
   ],
   "source": [
    "# Organize variables by attributes: animal, intake, outcome, datetime\n",
    "\n",
    "def check_type_date(name: str):\n",
    "    \"\"\"Checks if a column is a datetime or timedelta type by searching the name for keywords\n",
    "\n",
    "    Args:\n",
    "        name (str): The string to be checked\n",
    "\n",
    "    Returns:\n",
    "        Match|None: A Match object if a match is found\n",
    "    \"\"\"      \n",
    "    return re.search(r'.*date|month|duration.*', name)\n",
    "\n",
    "animal_vars = [\n",
    "    'animal_type',\n",
    "    'primary_color',\n",
    "    'secondary_color',\n",
    "    'sex',\n",
    "]\n",
    "intake_vars = [x for x in df.columns if 'intake' in x and not check_type_date(x)]\n",
    "outcome_vars = [x for x in df.columns if 'outcome' in x and not check_type_date(x)]\n",
    "datetime_vars = [x for x in df.columns if check_type_date(x)]\n",
    "geography_vars = [\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'geopoint',\n",
    "    'crossing',\n",
    "    'jurisdiction'\n",
    "]\n",
    "print(animal_vars, intake_vars, outcome_vars, datetime_vars, geography_vars, sep='\\n')\n",
    "vars_dict = {\n",
    "    'animal': animal_vars,\n",
    "    'intake': intake_vars,\n",
    "    'outcome': outcome_vars,\n",
    "    'datetime': datetime_vars,\n",
    "    'geography': geography_vars\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce53a9a",
   "metadata": {},
   "source": [
    "#### Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e4f71055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts for each variable and print to a CSV for visual inspection\n",
    "for vars in vars_dict.values():\n",
    "    for var in vars:\n",
    "        df[var].value_counts().to_csv(get_path_obj(data_dir, 'variable counts', f'{var}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d569d226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export animal names to CSV for visual inspection\n",
    "df.loc[~df.animal_name.isna()][['animal_id', 'animal_name']].to_csv(get_path_obj(data_dir, 'raw_animal_names.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b88da226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export animal names with numbers in them for visual inspection\n",
    "df.loc[df.animal_name.str.contains(r'.*\\d.*', regex=True, na=False), ['animal_id', 'animal_name']].to_csv(get_path_obj(data_dir, 'raw_number_names.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a731a9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export crossings which are missing zip codes to CSV for inspection\n",
    "df_crossing = df.loc[~df.crossing.str.contains(r'\\b\\d{5} *$', regex=True)]\n",
    "df_crossing.loc[~df_crossing.crossing.str.contains(r'TRANSFER', regex=True), ['animal_id', 'crossing']].to_csv(get_path_obj(data_dir, 'raw_crossing_wo_zip.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d4cbcc",
   "metadata": {},
   "source": [
    "## Cleaning and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cd9f43",
   "metadata": {},
   "source": [
    "#### Fix/remove data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0f47feea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['animal_id', 'animal_name', 'animal_type', 'primary_color',\n",
       "       'secondary_color', 'sex', 'date_of_birth', 'intake_date',\n",
       "       'intake_condition', 'intake_type', 'intake_subtype',\n",
       "       'reason_for_intake', 'outcome_date', 'crossing', 'jurisdiction',\n",
       "       'outcome_type', 'outcome_subtype', 'latitude', 'longitude',\n",
       "       'intake_is_dead', 'outcome_is_dead', 'geopoint', 'intake_duration',\n",
       "       'is_current_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove superfluous columns\n",
    "df_clean = df.drop(['was_outcome_alive'], axis=1)\n",
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a7b7fe64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitude columns do not match\n"
     ]
    }
   ],
   "source": [
    "# Compare latitude and longitude against geopoint\n",
    "\n",
    "def check_lat_long():\n",
    "    \"\"\"Checks the \"latitude\" and \"longitude\" columns against the \"geopoint\" column to see if they match.\n",
    "    Raises an AssertionError if they do not.\n",
    "    \"\"\"    \n",
    "    df_clean['lat_from_geopoint'] = df.geopoint.str.split(', ').str[0].astype('float64')\n",
    "    df_clean['long_from_geopoint'] = df.geopoint.str.split(', ').str[1].astype('float64')\n",
    "\n",
    "    errors = []\n",
    "    try: \n",
    "        assert df_clean.latitude.equals(df_clean.lat_from_geopoint), 'Latitude columns do not match'\n",
    "    except AssertionError as err:\n",
    "        errors.append(err)\n",
    "    try: \n",
    "        assert df_clean.longitude.equals(df_clean.long_from_geopoint), 'Longitude columns do not match'\n",
    "    except AssertionError as err:\n",
    "        errors.append(err)\n",
    "    if errors:\n",
    "        return errors\n",
    "    else:\n",
    "        return ['Columns match']\n",
    "\n",
    "check = check_lat_long()\n",
    "print(*check, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "922479db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns match\n"
     ]
    }
   ],
   "source": [
    "# Update latitude, longitude, from geopoint\n",
    "if check[0] != 'Columns match':\n",
    "    df_clean.latitude = df_clean.lat_from_geopoint\n",
    "    df_clean.longitude = df_clean.long_from_geopoint\n",
    "check = check_lat_long()\n",
    "print(*check, sep='\\n')\n",
    "if check[0] == 'Columns match':\n",
    "    df_clean = df_clean.drop(['lat_from_geopoint', 'long_from_geopoint', 'geopoint'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4cb16af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set specific columns' types to boolean\n",
    "df_clean.intake_is_dead = df.intake_is_dead.apply(lambda x: False if x in ['Alive on Intake',] else True)\n",
    "df_clean.is_current_month = df_clean.is_current_month.astype(bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a5979da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check intake and outcome dates against intake_duration\n",
    "df_clean['duration'] = df.outcome_date - df.intake_date\n",
    "intake_duration_series = pd.to_timedelta(df.intake_duration, unit='day')\n",
    "\n",
    "assert df_clean.duration.equals(intake_duration_series), '\"Intake duration\", \"Intake date\", \"Outcome date\" are inconsistent'\n",
    "\n",
    "df_clean.intake_duration = pd.to_timedelta(df.intake_duration, unit='day')\n",
    "df_clean.drop('duration', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fd1bc2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Dead on or shortly after arrival\" (as indicated by name): 14\n"
     ]
    }
   ],
   "source": [
    "# Find animals whose names indicate that they were deceased on or shortly after arrival as indicated by name\n",
    "\n",
    "filter_doa = df_clean.animal_name.str.contains(r'\\bDOA|DEAD\\b', regex=True, na=False)\n",
    "not_dead = [  # These names are ambiguous, since they are indicated as \"alive on intake\" and not \"dead on outcome\"\n",
    "    '*DEAD*BABADOOK',\n",
    "    '*DEAD*HAZEL',\n",
    "    '*DEAD CHOMPS',\n",
    "    '*DEAD*MAUI',\n",
    "    '*DEAD-TEDDY',\n",
    "]\n",
    "df_doa = df_clean.loc[(filter_doa) & ~(df_clean.animal_name.isin(not_dead))]\n",
    "print('\"Dead on or shortly after arrival\" (as indicated by name):', df_doa.shape[0])\n",
    "\n",
    "# Export details about these animals to a CSV file\n",
    "df_doa[['animal_id', 'outcome_type', 'outcome_subtype', 'intake_date', 'outcome_date']].to_csv(get_path_obj(data_dir, 'processed_dead_by_name.csv'), index=False)\n",
    "\n",
    "# Remove the \"dead\" indicator from their name\n",
    "df_doa.loc[:,'animal_name'] = df_doa.animal_name.str.replace(r'^\\**(?:DEAD|DOA)\\** *', '', regex=True)\n",
    "df_clean.loc[df_clean.animal_id.isin(df_doa.animal_id), 'animal_name'] = df_doa.animal_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1859df69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix \"alive on intake\" and \"outcome is dead\" values for animals who were dead on arrival\n",
    "ids = [\n",
    "    'A717145',\n",
    "    'A717146'\n",
    "]\n",
    "df_clean.loc[df_clean.animal_id.isin(ids), 'intake_is_dead'] = True\n",
    "df_clean.loc[df_clean.animal_id.isin(ids), 'outcome_is_dead'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "201cefa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove blank spaces from the beginning and end of names\n",
    "df_clean.animal_name = df_clean.animal_name.str.replace('^\\\\** +', '*', regex=True)\n",
    "df_clean.animal_name = df_clean.animal_name.str.replace(' +$', '', regex=True)\n",
    "\n",
    "assert df_clean.animal_name.str.contains('^\\\\* +', regex=True, na=False).sum() == 0, 'Names starting with blanks found'\n",
    "assert df_clean.animal_name.str.contains(' +$', regex=True, na=False).sum() == 0, 'Names ending with blanks found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "586c9da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove animal ID from animal name, if necessary\n",
    "\n",
    "def check_id_in_name(row):\n",
    "    string = row.animal_name\n",
    "    if not pd.isna(string):\n",
    "        id = re.search(r'\\d+', row.animal_id)\n",
    "        if id:\n",
    "            pattern = r'\\w?' + id.group()\n",
    "            return bool(re.search(pattern, string))\n",
    "    return False\n",
    "\n",
    "def remove_id_from_name(row):\n",
    "    string = row.animal_name\n",
    "    if not pd.isna(string):\n",
    "        id_ = row.animal_id\n",
    "        num_id = re.search(r\"\\d+\", id_)\n",
    "        if num_id:\n",
    "            pattern = fr'\\w?{num_id.group()}'\n",
    "            return re.sub(pattern, '', string)\n",
    "    return string\n",
    "\n",
    "name_filter = df_clean.apply(check_id_in_name, axis=1)\n",
    "df_clean.loc[name_filter, 'animal_name'] = df_clean.loc[name_filter].apply(remove_id_from_name, axis=1)\n",
    "assert df_clean.apply(check_id_in_name, axis=1).sum() == 0, 'Names with IDs found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4aa07359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter legitimate names (e.g. \"50 CENT\") out of the names with numbers and nullify names with numbers\n",
    "\n",
    "legit_names = [\n",
    "    '50 CENT',\n",
    "    'MARSHAL MATHERS 4TH',\n",
    "    '7-UP'\n",
    "]\n",
    "\n",
    "def remove_names_with_numbers(row):\n",
    "    string = row.animal_name\n",
    "    pattern = r'\\d+'\n",
    "    if re.search(pattern, string) and string.strip('*') not in legit_names:\n",
    "        return np.nan\n",
    "    return string\n",
    "\n",
    "number_names = df_clean.animal_name.str.contains(r'\\d', regex=True, na=False)\n",
    "df_clean.loc[number_names, 'animal_name'] = df_clean.loc[number_names].apply(remove_names_with_numbers, axis=1)\n",
    "\n",
    "number_names = df_clean.animal_name.str.contains(r'\\d', regex=True, na=False)\n",
    "legit_number_names = df_clean.animal_name.str.strip('*').isin(legit_names)\n",
    "assert df_clean.loc[(number_names) & ~(legit_number_names)].shape[0] == 0, 'Illegitimate number names found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8eaae678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove uncaught blank names\n",
    "df_clean.loc[df.animal_name.str.contains(r'^\\* *$', regex=True, na=False), 'animal_name'] = np.nan\n",
    "\n",
    "assert df_clean.animal_name.str.contains(r'^\\* *$', regex=True, na=False).sum() == 0, 'Uncaught blank names found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "95188a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove periods from \"crossing\" values\n",
    "\n",
    "# Remove periods from end of string\n",
    "df_clean.crossing = df_clean.crossing.str.replace(r'\\.$', '', regex=True)\n",
    "\n",
    "# Remove periods sandwiched between non-whitespace characters\n",
    "df_clean.crossing = df_clean.crossing.str.replace(r'(\\w)(\\.)(\\w)', r'\\1 \\3', regex=True)\n",
    "\n",
    "# Remove all other periods\n",
    "df_clean.crossing = df_clean.crossing.str.replace('.', '')\n",
    "\n",
    "assert df_clean.loc[df_clean.crossing.str.contains('.', regex=False), 'crossing'].sum() == 0, 'Crossings with periods found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "279817dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"&\" and \"AND\" with \"/\"\n",
    "df_clean.crossing = df_clean.crossing.str.replace('&', '/')\n",
    "df_clean.crossing = df_clean.crossing.str.replace(r'(\\s)(AND)(\\s)', r'\\1/\\3', regex=True)\n",
    "\n",
    "condition_1 = df_clean.crossing.str.contains('&').sum() == 0\n",
    "condition_2 = df_clean.crossing.str.contains(r'\\sAND\\s', regex=True).sum() == 0\n",
    "assert condition_1 and condition_2, 'Crossings with \"&\" or \"AND\" found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "773e5f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix \"crossing\" values so that \"/\" is always enclosed by spaces\n",
    "\n",
    "def refactor_slash(string: str):\n",
    "    array = string.split('/')\n",
    "    array = [s.strip() for s in array]\n",
    "    return ' / '.join(array)\n",
    "\n",
    "df_clean.crossing = df_clean.crossing.apply(refactor_slash)\n",
    "assert df_clean.crossing.str.contains(r'\\w/\\w', regex=True).sum() == 0, 'Crossings with sandwiched \"/\" found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0ccdeef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"STREET\", \"ROAD\", \"AVENUE\" with their appropriate abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7040e466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix all references to \"Pacific Coast Highway\"\n",
    "\n",
    "# Replace \"PCH HWY\" with \"PACIFIC COAST HWY\"\n",
    "df_clean.crossing = df_clean.crossing.str.replace('PCH HWY', 'PACIFIC COAST HWY')\n",
    "\n",
    "# Replace \"PACIFIC COAST HIGHWAY\" with \"PACIFIC COAST HWY\"\n",
    "df_clean.crossing = df_clean.crossing.str.replace('PACIFIC COAST HIGHWAY', 'PACIFIC COAST HWY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2ed8edcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change \"LBB\" to \"LONG BEACH BLVD\" in \"crossing\"\n",
    "df_clean.crossing = df_clean.crossing.str.replace('LBB', 'LONG BEACH BLVD')\n",
    "\n",
    "assert df_clean.crossing.str.contains('LBB').sum() == 0, 'Crossings with \"LBB\" found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "416623cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix references to \"Long Beach\"\n",
    "\n",
    "# Change \"LB\" to \"LONG BEACH\" for \"crossing\" values\n",
    "df_clean.crossing = df_clean.crossing.str.replace(r'\\bLB\\b', 'LONG BEACH', regex=True)\n",
    "\n",
    "# Change \"LONGBEACH\" to \"LONG BEACH\"\n",
    "df_clean.crossing = df_clean.crossing.str.replace('LONGBEACH', 'LONG BEACH', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e9a4d92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"BLK\" with \"BLOCK\" in \"crossing\"\n",
    "df_clean.crossing = df_clean.crossing.str.replace(r'BLK\\b', 'BLOCK', regex=True)\n",
    "df_clean.crossing = df_clean.crossing.str.replace(r'BLK[KL]\\b', 'BLOCK', regex=True)\n",
    "df_clean.crossing = df_clean.crossing.str.replace(r'BLKW\\b', 'BLOCK W', regex=True)\n",
    "df_clean.crossing = df_clean.crossing.str.replace(r'BLKE\\b', 'BLOCK E', regex=True)\n",
    "df_clean.loc[2023, 'crossing'] = '3700 BLOCK ELM AVE,LONG BEACH, CA 90807'\n",
    "df_clean.loc[26272, 'crossing'] = '20100 BLOCK BOUMA CT, CERRITOS, CA 90703'\n",
    "df_clean.loc[29902, 'crossing'] = '300 BLOCK MEDITERRANEAN WAY LONG BEACH, CA 90802'\n",
    "df_clean.loc[32825, 'crossing'] = '900 BLOCK MAINE AVE, LONG BEACH, CA 90813'\n",
    "\n",
    "assert df_clean.crossing.str.contains('BLK').sum() == 0, 'Crossings with with word \"BLK\" found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "81e8db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix \"crossing\" values where \"BLOCK\" occurs more than once\n",
    "df_clean.loc[910, 'crossing'] = '300 BLOCK E JANICE ST, LONG BEACH, CA 90805'\n",
    "df_clean.loc[1003, 'crossing'] = '300 BLOCK ROYCROFT AVE, LONG BEACH, CA 90814'  # Fixed zip code\n",
    "df_clean.crossing = df_clean.crossing.str.replace('BLOCK LINDEN BLOCK', 'LINDEN BLOCK')\n",
    "\n",
    "assert df_clean.crossing.str.contains(r'(?:BLOCK.*){2,}').sum() == 0, 'Crossings with multiple occurences of \"BLOCK\" found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2d59794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix \"crossing\" values where \"BLOCK\" is sandwiched against another non-whitespace character\n",
    "df_clean.crossing = df_clean.crossing.str.replace(r'(\\w)(BLOCK)', r'/1 /2', regex=True)\n",
    "df_clean.crossing = df_clean.crossing.str.replace(r'(BLOCK)(\\w)', r'/1 /2', regex=True)\n",
    "\n",
    "condition_1 = df_clean.crossing.str.contains(r'\\wBLOCK').sum() == 0\n",
    "condition_2 = df_clean.crossing.str.contains(r'BLOCK\\w').sum() == 0\n",
    "\n",
    "assert condition_1 and condition_2, 'Crossings found where \"BLOCK\" sandwiched against leading or trailing non-whitespace character'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "516d0865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix \"crossing\" values that have \"BKL\"\n",
    "df_clean.crossing = df_clean.crossing.str.replace('BKL', 'BLOCK')\n",
    "\n",
    "assert df_clean.crossing.str.contains('BKL').sum() == 0, 'Crossings with \"BKL\" found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a8f1e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace two or more consecutive spaces with a single space in \"crossing\"\n",
    "df_clean.crossing = df_clean.crossing.str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "assert df_clean.crossing.str.contains(r'\\s\\s+', regex=True).sum() == 0, 'Crossings with multiple whitespaces found'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58f4ae7",
   "metadata": {},
   "source": [
    "#### Add features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c85dd200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an \"age at intake\" column\n",
    "df_clean['age_at_intake'] = df.intake_date - df.date_of_birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "86af5575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an \"age at outcome\" column\n",
    "df_clean['age_at_outcome'] = df.outcome_date - df.date_of_birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e3102cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a \"has_name\" column\n",
    "df_clean['has_name'] = ~df.animal_name.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d227b33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a \"named_by_shelter\" column\n",
    "df_clean['named_by_shelter'] = df.animal_name.str.contains(r'\\*').astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9e1ff525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"named by shelter indicator\" from animal name\n",
    "df_clean.animal_name = df_clean.animal_name.str.replace(r'^\\*', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "201eaa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export processed animal names to CSV\n",
    "df_clean.loc[:, ['animal_id', 'animal_name']].to_csv(get_path_obj(data_dir, 'processed_animal_names.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a836fecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export unique processed crossings to CSV\n",
    "df_clean['crossing'].value_counts().to_csv(get_path_obj(data_dir, 'processed_crossings_unique.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "984e79bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "animal_id                     object\n",
       "animal_name                   object\n",
       "animal_type                   object\n",
       "primary_color                 object\n",
       "secondary_color               object\n",
       "sex                           object\n",
       "date_of_birth         datetime64[ns]\n",
       "intake_date           datetime64[ns]\n",
       "intake_condition              object\n",
       "intake_type                   object\n",
       "intake_subtype                object\n",
       "reason_for_intake             object\n",
       "outcome_date          datetime64[ns]\n",
       "crossing                      object\n",
       "jurisdiction                  object\n",
       "outcome_type                  object\n",
       "outcome_subtype               object\n",
       "latitude                     float64\n",
       "longitude                    float64\n",
       "intake_is_dead                  bool\n",
       "outcome_is_dead                 bool\n",
       "intake_duration      timedelta64[ns]\n",
       "is_current_month                bool\n",
       "age_at_intake        timedelta64[ns]\n",
       "age_at_outcome       timedelta64[ns]\n",
       "has_name                        bool\n",
       "named_by_shelter                bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data types\n",
    "df_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "daae711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export processed data to CSV\n",
    "df_clean.to_csv(get_path_obj(processed_data_path), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6724d88",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab47d07",
   "metadata": {},
   "source": [
    "## Deeper analysis and modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c68449",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beddd7d",
   "metadata": {},
   "source": [
    "## Insights and recommendations\n",
    "\n",
    "### Insights\n",
    "\n",
    "### Recommedations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b330f07",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "*This report can also be found [here](../products/report.md).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1d8aae",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
